{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b808c94-c963-4aa1-a610-a77cf49cb412",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-23 12:14:37.466302: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-12-23 12:14:37.466351: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-12-23 12:14:37.467386: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import string\n",
    "from IPython.display import display, HTML\n",
    "import keras\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, losses, callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "645bc878-77e1-48e0-94b7-5dd5033b6d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow is not using the GPU\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(\"TensorFlow is using the GPU\")\n",
    "else:\n",
    "    print(\"TensorFlow is not using the GPU\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dda63c9-b858-4e14-81d7-4b506b8b2f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAXLEN = 80\n",
    "VOCAB_SIZE = 10000\n",
    "EMBEDDING_DIM = 256\n",
    "N_HEADS = 2\n",
    "KEY_DIM = 256\n",
    "FEED_FORWARD_DIM = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501f1e2d-586e-43d7-a802-2a831d5e3421",
   "metadata": {},
   "source": [
    "## Prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81e9254b-0976-4e38-ad18-1846be03bf6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>country</th>\n",
       "      <th>description</th>\n",
       "      <th>designation</th>\n",
       "      <th>points</th>\n",
       "      <th>price</th>\n",
       "      <th>province</th>\n",
       "      <th>region_1</th>\n",
       "      <th>region_2</th>\n",
       "      <th>taster_name</th>\n",
       "      <th>taster_twitter_handle</th>\n",
       "      <th>title</th>\n",
       "      <th>variety</th>\n",
       "      <th>winery</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Italy</td>\n",
       "      <td>Aromas include tropical fruit, broom, brimston...</td>\n",
       "      <td>Vulkà Bianco</td>\n",
       "      <td>87</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sicily &amp; Sardinia</td>\n",
       "      <td>Etna</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kerin O’Keefe</td>\n",
       "      <td>@kerinokeefe</td>\n",
       "      <td>Nicosia 2013 Vulkà Bianco  (Etna)</td>\n",
       "      <td>White Blend</td>\n",
       "      <td>Nicosia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>This is ripe and fruity, a wine that is smooth...</td>\n",
       "      <td>Avidagos</td>\n",
       "      <td>87</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Douro</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Roger Voss</td>\n",
       "      <td>@vossroger</td>\n",
       "      <td>Quinta dos Avidagos 2011 Avidagos Red (Douro)</td>\n",
       "      <td>Portuguese Red</td>\n",
       "      <td>Quinta dos Avidagos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>US</td>\n",
       "      <td>Tart and snappy, the flavors of lime flesh and...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Paul Gregutt</td>\n",
       "      <td>@paulgwine</td>\n",
       "      <td>Rainstorm 2013 Pinot Gris (Willamette Valley)</td>\n",
       "      <td>Pinot Gris</td>\n",
       "      <td>Rainstorm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>US</td>\n",
       "      <td>Pineapple rind, lemon pith and orange blossom ...</td>\n",
       "      <td>Reserve Late Harvest</td>\n",
       "      <td>87</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>Lake Michigan Shore</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Alexander Peartree</td>\n",
       "      <td>NaN</td>\n",
       "      <td>St. Julian 2013 Reserve Late Harvest Riesling ...</td>\n",
       "      <td>Riesling</td>\n",
       "      <td>St. Julian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>US</td>\n",
       "      <td>Much like the regular bottling from 2012, this...</td>\n",
       "      <td>Vintner's Reserve Wild Child Block</td>\n",
       "      <td>87</td>\n",
       "      <td>65.0</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Paul Gregutt</td>\n",
       "      <td>@paulgwine</td>\n",
       "      <td>Sweet Cheeks 2012 Vintner's Reserve Wild Child...</td>\n",
       "      <td>Pinot Noir</td>\n",
       "      <td>Sweet Cheeks</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   country                                        description  \\\n",
       "0           0     Italy  Aromas include tropical fruit, broom, brimston...   \n",
       "1           1  Portugal  This is ripe and fruity, a wine that is smooth...   \n",
       "2           2        US  Tart and snappy, the flavors of lime flesh and...   \n",
       "3           3        US  Pineapple rind, lemon pith and orange blossom ...   \n",
       "4           4        US  Much like the regular bottling from 2012, this...   \n",
       "\n",
       "                          designation  points  price           province  \\\n",
       "0                        Vulkà Bianco      87    NaN  Sicily & Sardinia   \n",
       "1                            Avidagos      87   15.0              Douro   \n",
       "2                                 NaN      87   14.0             Oregon   \n",
       "3                Reserve Late Harvest      87   13.0           Michigan   \n",
       "4  Vintner's Reserve Wild Child Block      87   65.0             Oregon   \n",
       "\n",
       "              region_1           region_2         taster_name  \\\n",
       "0                 Etna                NaN       Kerin O’Keefe   \n",
       "1                  NaN                NaN          Roger Voss   \n",
       "2    Willamette Valley  Willamette Valley        Paul Gregutt   \n",
       "3  Lake Michigan Shore                NaN  Alexander Peartree   \n",
       "4    Willamette Valley  Willamette Valley        Paul Gregutt   \n",
       "\n",
       "  taster_twitter_handle                                              title  \\\n",
       "0          @kerinokeefe                  Nicosia 2013 Vulkà Bianco  (Etna)   \n",
       "1            @vossroger      Quinta dos Avidagos 2011 Avidagos Red (Douro)   \n",
       "2           @paulgwine       Rainstorm 2013 Pinot Gris (Willamette Valley)   \n",
       "3                   NaN  St. Julian 2013 Reserve Late Harvest Riesling ...   \n",
       "4           @paulgwine   Sweet Cheeks 2012 Vintner's Reserve Wild Child...   \n",
       "\n",
       "          variety               winery  \n",
       "0     White Blend              Nicosia  \n",
       "1  Portuguese Red  Quinta dos Avidagos  \n",
       "2      Pinot Gris            Rainstorm  \n",
       "3        Riesling           St. Julian  \n",
       "4      Pinot Noir         Sweet Cheeks  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_data = pd.read_csv(\"Data/winemag-data-130k-v2.csv\")\n",
    "wine_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23032bca-21b8-4ea9-bbad-72745180b8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_data.to_json(\"Data/winemag-data-130k-v2.json\", orient=\"records\", indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be750eba-1ce9-49f9-b42d-6f97a9fd723d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the full dataset\n",
    "with open(\"Data/winemag-data-130k-v2.json\") as json_data:\n",
    "    wine_data = json.load(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8589fa5c-438b-4e9c-9366-04ed7fc69391",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data = [\n",
    "    \"wine_data: \"\n",
    "    + x[\"country\"] + \" : \"\n",
    "    + x[\"province\"] + \" : \"\n",
    "    + x[\"variety\"] + \" : \"\n",
    "    + x[\"description\"] + \" : \"\n",
    "    for x in wine_data\n",
    "    if x[\"country\"] is not None\n",
    "    and x[\"province\"] is not None\n",
    "    and x[\"variety\"] is not None\n",
    "    and x[\"description\"] is not None\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7871a74b-71c0-4033-9092-9883ec24aa4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129907 load_dataset\n"
     ]
    }
   ],
   "source": [
    "number_wines = len(filtered_data)\n",
    "print(f\"{number_wines} load_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57e80a56-6923-4807-bd68-53c5e34a544d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wine_data: US : California : Pinot Noir : Oak and earth intermingle around robust aromas of wet forest floor in this vineyard-designated Pinot that hails from a high-elevation site. Small in production, it offers intense, full-bodied raspberry and blackberry steeped in smoky spice and smooth texture. : \n"
     ]
    }
   ],
   "source": [
    "sample = filtered_data[25]\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87546bf-6cf3-4f32-9a23-3e3997d93bdf",
   "metadata": {},
   "source": [
    "## tokenize the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de7e6618-2fc0-491a-a831-d7d4af4916cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_punt(s):\n",
    "    s = re.sub(f\"([{string.punctuation}, '\\n'])\", r\" \\1 \", s)\n",
    "    s =  re.sub(\" +\",\" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63dfc10c-936a-441b-b915-e231639efeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = [pad_punt(x) for x in filtered_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b47a9177-ded3-4841-801f-b8c6bba5354a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample=text_data[25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a01f6e2-3842-4df9-b631-c5e450166e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-17 08:05:17.788925: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-17 08:05:17.828555: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-17 08:05:17.828756: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-17 08:05:17.830292: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-17 08:05:17.830485: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-17 08:05:17.830651: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-17 08:05:19.912372: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-17 08:05:19.912550: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-17 08:05:19.912699: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-17 08:05:19.912800: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9311 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "text_ds = tf.data.Dataset.from_tensor_slices(text_data).batch(32).shuffle(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c947646f-a7ed-421e-a19b-79d832ab9631",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorize = layers.TextVectorization(\n",
    "                    standardize = \"lower\",\n",
    "                    max_tokens=VOCAB_SIZE,\n",
    "                    output_mode = \"int\",\n",
    "                    output_sequence_length= MAXLEN + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a68ef29f-dfd7-4ade-8f55-625a43fdfe59",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorize.adapt(text_ds)\n",
    "vocab = vectorize.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f29783ae-0416-40c5-9f03-789e3da0a268",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_input(text):\n",
    "    text = tf.expand_dims(text, -1)\n",
    "    tokenized_sentence = vectorize(text)\n",
    "    x = tokenized_sentence[:,:-1]\n",
    "    y = tokenized_sentence[:, 1:]\n",
    "    return x, y\n",
    "train_ds = text_ds.map(prep_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8933eaf4-a1b4-4097-8482-6bf96a39c9af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e2632f20-1f2b-4e83-a713-14402e183c69",
   "metadata": {},
   "source": [
    "## AttentionHead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "627855da-4c33-4fb1-a618-9ae9eb132253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# layers.MultiHeadAttention(num_heads = 4,\n",
    "#                           key_dim = 128,\n",
    "#                           value_dim = 64,\n",
    "#                           output_shape = 128\n",
    "#                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1708a1bd-3a6f-42b1-b7c5-bde7a12e03c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "       [0, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "       [0, 0, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 1, 1, 1, 1, 1],\n",
       "       [0, 0, 0, 0, 1, 1, 1, 1, 1, 1],\n",
       "       [0, 0, 0, 0, 0, 1, 1, 1, 1, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 1, 1, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 1, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]], dtype=int32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Causal_Attn_Mask(batch_size, n_dest, n_src, dtype):\n",
    "    i = tf.range(n_dest)[:, None]\n",
    "    j = tf.range(n_src)\n",
    "    m = i >= j - n_src + n_dest\n",
    "    mask = tf.cast(m, dtype)\n",
    "    mask = tf.reshape(mask, [1, n_dest, n_src])\n",
    "    mult = tf.concat([tf.expand_dims(batch_size, - 1), tf.constant([1,1],\n",
    "                     dtype=tf.int32)], 0)\n",
    "    return tf.tile(mask, mult)\n",
    "np.transpose(Causal_Attn_Mask(1,10,10, dtype=tf.int32)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3805e82-0c0d-45d7-ad65-0f7bf7279985",
   "metadata": {},
   "source": [
    "## TransformerBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb6c488f-ad73-435e-93c5-330be33ffe24",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(layers.Layer):\n",
    "    def __init__(self, num_heads, key_dim, ff_dim, embed_dim, rate= 0.1):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.key_dim = key_dim\n",
    "        self.embed_dim = embed_dim\n",
    "        self.ff_dim = ff_dim\n",
    "        self.rate = rate\n",
    "        self.attn = layers.MultiHeadAttention(num_heads, key_dim, output_shape=embed_dim)\n",
    "        self.dropout1 = layers.Dropout(self.rate)\n",
    "        self.layerNorm = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.ffn = keras.Sequential(\n",
    "            [layers.Dense(self.ff_dim, activation=\"relu\"), layers.Dense(self.embed_dim),]\n",
    "        )\n",
    "        self.dropout2 = layers.Dropout(self.rate)\n",
    "        self.layerNorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        input_shape = tf.shape(inputs)\n",
    "        batch_size = input_shape[0]\n",
    "        sequence_length = input_shape[1]\n",
    "        causal_mask = Causal_Attn_Mask(batch_size, sequence_length, sequence_length, tf.bool)\n",
    "        attention_output, attention_scores = self.attn(inputs,\n",
    "                                            inputs,\n",
    "                                            attention_mask = causal_mask,\n",
    "                                            return_attention_scores = True)\n",
    "        attention_output = self.dropout1(attention_output)\n",
    "        out_1 = self.layerNorm(inputs + attention_output)\n",
    "        ffn = self.ffn(out_1)\n",
    "        ffn_out = self.dropout2(ffn)\n",
    "        return (self.layerNorm2(out_1 + ffn_out), attention_scores)\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update(\n",
    "            {\n",
    "                \"key_dim\": self.key_dim,\n",
    "                \"embed_dim\": self.embed_dim,\n",
    "                \"num_heads\": self.num_heads,\n",
    "                \"ff_dim\": self.ff_dim,\n",
    "                \"rate\": self.rate,\n",
    "            }\n",
    "        )\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6af2ce63-32cd-4308-b0ed-0f25f78ac533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TransformerEncoder.call(\n",
    "#     inputs,\n",
    "#     padding_mask=None,\n",
    "#     attention_mask=None,\n",
    "#     training=None,\n",
    "#     return_attention_scores=False,\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c754a3c-b07d-4995-8030-9fa8ac55da6e",
   "metadata": {},
   "source": [
    "## PositioningEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "583e2b43-e3cf-4f71-a8ac-607a9f458b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenAndPositionEmbedding(layers.Layer):\n",
    "    def __init__(self,maxlen, vocab_size, embed_dim):\n",
    "        super(TokenAndPositionEmbedding, self).__init__()\n",
    "        self.maxlen = maxlen\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_dim = embed_dim\n",
    "        self.token_emb = layers.Embedding(input_dim = vocab_size, output_dim = embed_dim)\n",
    "        self.pos_emb = layers.Embedding(input_dim = maxlen, output_dim = embed_dim)\n",
    "        \n",
    "    def call(self, x):\n",
    "        maxlen = tf.shape(x)[-1]\n",
    "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
    "        positions = self.pos_emb(positions)\n",
    "        x = self.token_emb(x)\n",
    "        return x + positions\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update(\n",
    "            {\n",
    "                \"max_len\": self.maxlen,\n",
    "                \"vocab_size\": self.vocab_size,\n",
    "                \"embed_dim\": self.embed_dim,\n",
    "            }\n",
    "        )\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d2bea77f-9363-4db9-90ca-57a106807118",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = layers.Input(shape=(None,), dtype=tf.int32)\n",
    "x = TokenAndPositionEmbedding(MAXLEN, VOCAB_SIZE, EMBEDDING_DIM)(inputs)\n",
    "x, attention_scores = TransformerBlock(N_HEADS, KEY_DIM, EMBEDDING_DIM, FEED_FORWARD_DIM)(x)\n",
    "outputs = layers.Dense(VOCAB_SIZE, activation =\"softmax\")(x)\n",
    "gpt = models.Model(inputs = inputs, outputs=[outputs, attention_scores])\n",
    "gpt.compile(\"adam\", loss=[losses.SparseCategoricalCrossentropy(), None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c5596c99-05db-4209-87ed-c1a9f04ba63d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, None)]            0         \n",
      "                                                                 \n",
      " token_and_position_embeddi  (None, None, 256)         2580480   \n",
      " ng (TokenAndPositionEmbedd                                      \n",
      " ing)                                                            \n",
      "                                                                 \n",
      " transformer_block (Transfo  ((None, None, 256),       658688    \n",
      " rmerBlock)                   (None, 2, None, None))             \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, None, 10000)       2570000   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5809168 (22.16 MB)\n",
      "Trainable params: 5809168 (22.16 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gpt.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "85d8a9df-61d8-4cac-bc10-c99eda10d3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"./checkpoint/checkpoints.ckpt\"\n",
    "ModelcheckPoint = keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_best_only=True,\n",
    "                                                 save_freq=\"epoch\",\n",
    "                                                 verbose=0,\n",
    "                                                 save_weights_only=True)\n",
    "EarlyStopping = keras.callbacks.EarlyStopping(monitor=\"loss\",\n",
    "                                             verbose=0,\n",
    "                                             mode=\"auto\",\n",
    "                                             patience=3,\n",
    "                                             min_delta=0.01,\n",
    "                                             )\n",
    "tensorboard = keras.callbacks.TensorBoard(log_dir=\"./logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3a72caa4-4d65-41bc-bb00-661e718bc8b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-17 08:05:51.478177: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f2020612d90 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-12-17 08:05:51.478224: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3060, Compute Capability 8.6\n",
      "2024-12-17 08:05:51.484373: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-12-17 08:05:52.004857: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8903\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1734422752.151215   12067 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4060/4060 [==============================] - ETA: 0s - loss: 2.2507 - dense_2_loss: 2.2507WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "4060/4060 [==============================] - 144s 33ms/step - loss: 2.2507 - dense_2_loss: 2.2507\n",
      "Epoch 2/15\n",
      "4060/4060 [==============================] - ETA: 0s - loss: 1.9558 - dense_2_loss: 1.9558WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "4060/4060 [==============================] - 98s 24ms/step - loss: 1.9558 - dense_2_loss: 1.9558\n",
      "Epoch 3/15\n",
      "4060/4060 [==============================] - ETA: 0s - loss: 1.8861 - dense_2_loss: 1.8861WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "4060/4060 [==============================] - 98s 24ms/step - loss: 1.8861 - dense_2_loss: 1.8861\n",
      "Epoch 4/15\n",
      "4060/4060 [==============================] - ETA: 0s - loss: 1.8446 - dense_2_loss: 1.8446WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "4060/4060 [==============================] - 98s 24ms/step - loss: 1.8446 - dense_2_loss: 1.8446\n",
      "Epoch 5/15\n",
      "4059/4060 [============================>.] - ETA: 0s - loss: 1.8143 - dense_2_loss: 1.8143WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "4060/4060 [==============================] - 96s 24ms/step - loss: 1.8142 - dense_2_loss: 1.8142\n",
      "Epoch 6/15\n",
      "4058/4060 [============================>.] - ETA: 0s - loss: 1.7908 - dense_2_loss: 1.7908WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "4060/4060 [==============================] - 96s 24ms/step - loss: 1.7908 - dense_2_loss: 1.7908\n",
      "Epoch 7/15\n",
      "4058/4060 [============================>.] - ETA: 0s - loss: 1.7719 - dense_2_loss: 1.7719WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "4060/4060 [==============================] - 98s 24ms/step - loss: 1.7721 - dense_2_loss: 1.7721\n",
      "Epoch 8/15\n",
      "4058/4060 [============================>.] - ETA: 0s - loss: 1.7565 - dense_2_loss: 1.7565WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "4060/4060 [==============================] - 93s 23ms/step - loss: 1.7564 - dense_2_loss: 1.7564\n",
      "Epoch 9/15\n",
      "4059/4060 [============================>.] - ETA: 0s - loss: 1.7427 - dense_2_loss: 1.7427WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "4060/4060 [==============================] - 94s 23ms/step - loss: 1.7426 - dense_2_loss: 1.7426\n",
      "Epoch 10/15\n",
      "4058/4060 [============================>.] - ETA: 0s - loss: 1.7305 - dense_2_loss: 1.7305WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "4060/4060 [==============================] - 98s 24ms/step - loss: 1.7306 - dense_2_loss: 1.7306\n",
      "Epoch 11/15\n",
      "4058/4060 [============================>.] - ETA: 0s - loss: 1.7198 - dense_2_loss: 1.7198WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "4060/4060 [==============================] - 95s 23ms/step - loss: 1.7200 - dense_2_loss: 1.7200\n",
      "Epoch 12/15\n",
      "4060/4060 [==============================] - ETA: 0s - loss: 1.7104 - dense_2_loss: 1.7104WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "4060/4060 [==============================] - 96s 24ms/step - loss: 1.7104 - dense_2_loss: 1.7104\n",
      "Epoch 13/15\n",
      "4059/4060 [============================>.] - ETA: 0s - loss: 1.7017 - dense_2_loss: 1.7017WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "4060/4060 [==============================] - 98s 24ms/step - loss: 1.7017 - dense_2_loss: 1.7017\n",
      "Epoch 14/15\n",
      "4058/4060 [============================>.] - ETA: 0s - loss: 1.6938 - dense_2_loss: 1.6938WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "4060/4060 [==============================] - 98s 24ms/step - loss: 1.6937 - dense_2_loss: 1.6937\n",
      "Epoch 15/15\n",
      "4059/4060 [============================>.] - ETA: 0s - loss: 1.6865 - dense_2_loss: 1.6865WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "4060/4060 [==============================] - 98s 24ms/step - loss: 1.6866 - dense_2_loss: 1.6866\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f23000e86a0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt.fit(train_ds,\n",
    "        epochs= 15,\n",
    "       callbacks=[ModelcheckPoint, EarlyStopping, tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7b4fd727-4aa5-4443-ade2-a99effd03777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "\n",
    "# # Check if GPU is available\n",
    "# if tf.config.list_physical_devices('GPU'):\n",
    "#     print(\"TensorFlow is using GPU.\")\n",
    "# else:\n",
    "#     print(\"TensorFlow is not using GPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb6c586-99fc-4b4d-9282-2c119563d419",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
