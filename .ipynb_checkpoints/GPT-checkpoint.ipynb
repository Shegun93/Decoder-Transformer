{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b808c94-c963-4aa1-a610-a77cf49cb412",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-16 11:49:25.150208: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:\n",
      "2024-12-16 11:49:25.150231: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-12-16 11:49:25.183302: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-16 11:49:25.925008: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:\n",
      "2024-12-16 11:49:25.925126: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:\n",
      "2024-12-16 11:49:25.925139: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import string\n",
    "from IPython.display import display, HTML\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, losses, callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9dda63c9-b858-4e14-81d7-4b506b8b2f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAXLEN = 80\n",
    "VOCAB_SIZE = 10000\n",
    "EMBEDDING_DIM = 256\n",
    "N_HEADS = 2\n",
    "KEY_DIM = 256\n",
    "FEED_FORWARD_DIM = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501f1e2d-586e-43d7-a802-2a831d5e3421",
   "metadata": {},
   "source": [
    "## Prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be750eba-1ce9-49f9-b42d-6f97a9fd723d",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/app/data/wine-reviews/winemag-data-130k-v2.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load the full dataset\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/app/data/wine-reviews/winemag-data-130k-v2.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m json_data:\n\u001b[1;32m      3\u001b[0m     wine_data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(json_data)\n",
      "File \u001b[0;32m~/anaconda3/envs/transfomer/lib/python3.9/site-packages/IPython/core/interactiveshell.py:310\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    305\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    308\u001b[0m     )\n\u001b[0;32m--> 310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/app/data/wine-reviews/winemag-data-130k-v2.json'"
     ]
    }
   ],
   "source": [
    "# Load the full dataset\n",
    "with open(\"/app/data/wine-reviews/winemag-data-130k-v2.json\") as json_data:\n",
    "    wine_data = json.load(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8589fa5c-438b-4e9c-9366-04ed7fc69391",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data = [\n",
    "    \"wine_data: \"\n",
    "    + x[\"country\"] + \" : \"\n",
    "    + x[\"province\"] + \" : \"\n",
    "    + x[\"variety\"] + \" : \"\n",
    "    + x[\"description\"] + \" : \"\n",
    "    for x in wine_data\n",
    "    if x[\"country\"] is not None\n",
    "    and x[\"province\"] is not None\n",
    "    and x[\"variety\"] is not None\n",
    "    and x[\"description\"] is not None\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7871a74b-71c0-4033-9092-9883ec24aa4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129907 load_dataset\n"
     ]
    }
   ],
   "source": [
    "number_wines = len(filtered_data)\n",
    "print(f\"{number_wines} load_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57e80a56-6923-4807-bd68-53c5e34a544d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wine_data: US : California : Pinot Noir : Oak and earth intermingle around robust aromas of wet forest floor in this vineyard-designated Pinot that hails from a high-elevation site. Small in production, it offers intense, full-bodied raspberry and blackberry steeped in smoky spice and smooth texture. : \n"
     ]
    }
   ],
   "source": [
    "sample = filtered_data[25]\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87546bf-6cf3-4f32-9a23-3e3997d93bdf",
   "metadata": {},
   "source": [
    "## tokenize the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de7e6618-2fc0-491a-a831-d7d4af4916cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_punt(s):\n",
    "    s = re.sub(f\"([{string.punctuation}, '\\n'])\", r\" \\1 \", s)\n",
    "    s =  re.sub(\" +\",\" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63dfc10c-936a-441b-b915-e231639efeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = [pad_punt(x) for x in filtered_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b47a9177-ded3-4841-801f-b8c6bba5354a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample=text_data[25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a01f6e2-3842-4df9-b631-c5e450166e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-16 11:09:44.956246: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-12-16 11:09:44.959156: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-12-16 11:09:44.959312: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-12-16 11:09:44.960456: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-12-16 11:09:44.960596: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-12-16 11:09:44.960722: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-12-16 11:09:45.505961: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-12-16 11:09:45.506138: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-12-16 11:09:45.506270: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-12-16 11:09:45.506390: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9349 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "text_ds = tf.data.Dataset.from_tensor_slices(text_data).batch(32).shuffle(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c947646f-a7ed-421e-a19b-79d832ab9631",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorize = layers.TextVectorization(\n",
    "                    standardize = \"lower\",\n",
    "                    max_tokens=VOCAB_SIZE,\n",
    "                    output_mode = \"int\",\n",
    "                    output_sequence_length= MAXLEN + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a68ef29f-dfd7-4ade-8f55-625a43fdfe59",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorize.adapt(text_ds)\n",
    "vocab = vectorize.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f29783ae-0416-40c5-9f03-789e3da0a268",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_input(text):\n",
    "    text = tf.expand_dims(text, -1)\n",
    "    tokenized_sentence = vectorize(text)\n",
    "    x = tokenized_sentence[:,:-1]\n",
    "    y = tokenized_sentence[:, 1:]\n",
    "    return x, y\n",
    "train_ds = text_ds.map(prep_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8933eaf4-a1b4-4097-8482-6bf96a39c9af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e2632f20-1f2b-4e83-a713-14402e183c69",
   "metadata": {},
   "source": [
    "## AttentionHead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "627855da-4c33-4fb1-a618-9ae9eb132253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# layers.MultiHeadAttention(num_heads = 4,\n",
    "#                           key_dim = 128,\n",
    "#                           value_dim = 64,\n",
    "#                           output_shape = 128\n",
    "#                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1708a1bd-3a6f-42b1-b7c5-bde7a12e03c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "       [0, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "       [0, 0, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 1, 1, 1, 1, 1],\n",
       "       [0, 0, 0, 0, 1, 1, 1, 1, 1, 1],\n",
       "       [0, 0, 0, 0, 0, 1, 1, 1, 1, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 1, 1, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 1, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]], dtype=int32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Causal_Attn_Mask(batch_size, n_dest, n_src, dtype):\n",
    "    i = tf.range(n_dest)[:, None]\n",
    "    j = tf.range(n_src)\n",
    "    m = i >= j - n_src + n_dest\n",
    "    mask = tf.cast(m, dtype)\n",
    "    mask = tf.reshape(mask, [1, n_dest, n_src])\n",
    "    mult = tf.concat([tf.expand_dims(batch_size, - 1), tf.constant([1,1],\n",
    "                     dtype=tf.int32)], 0)\n",
    "    return tf.tile(mask, mult)\n",
    "np.transpose(Causal_Attn_Mask(1,10,10, dtype=tf.int32)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3805e82-0c0d-45d7-ad65-0f7bf7279985",
   "metadata": {},
   "source": [
    "## TransformerBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cb6c488f-ad73-435e-93c5-330be33ffe24",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(layers.Layer):\n",
    "    def __init__(self, num_heads, key_dim, ff_dim, embed_dim, rate= 0.1):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.key_dim = key_dim\n",
    "        self.embed_dim = embed_dim\n",
    "        self.ff_dim = ff_dim\n",
    "        self.rate = rate\n",
    "        self.attn = layers.MultiHeadAttention(num_heads, key_dim, output_shape=embed_dim)\n",
    "        self.dropout1 = layers.Dropout(self.rate)\n",
    "        self.layerNorm = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.ffn = keras.Sequential(\n",
    "            [layers.Dense(self.ff_dim, activation=\"relu\"), layers.Dense(self.embed_dim),]\n",
    "        )\n",
    "        self.dropout2 = layers.Dropout(self.rate)\n",
    "        self.layerNorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        input_shape = tf.shape(inputs)\n",
    "        batch_size = input_shape[0]\n",
    "        sequence_length = input_shape[1]\n",
    "        causal_mask = Causal_Attn_Mask(batch_size, sequence_length, sequence_length, tf.bool)\n",
    "        attention_output, attention_scores = self.attn(inputs,\n",
    "                                            inputs,\n",
    "                                            attention_mask = causal_mask,\n",
    "                                            return_attention_scores = True)\n",
    "        attention_output = self.dropout1(attention_output)\n",
    "        out_1 = self.layerNorm(inputs + attention_output)\n",
    "        ffn = self.ffn(out_1)\n",
    "        ffn_out = self.dropout2(ffn)\n",
    "        return (self.layerNorm2(out_1 + ffn_out), attention_scores)\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update(\n",
    "            {\n",
    "                \"key_dim\": self.key_dim,\n",
    "                \"embed_dim\": self.embed_dim,\n",
    "                \"num_heads\": self.num_heads,\n",
    "                \"ff_dim\": self.ff_dim,\n",
    "                \"rate\": self.rate,\n",
    "            }\n",
    "        )\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6af2ce63-32cd-4308-b0ed-0f25f78ac533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TransformerEncoder.call(\n",
    "#     inputs,\n",
    "#     padding_mask=None,\n",
    "#     attention_mask=None,\n",
    "#     training=None,\n",
    "#     return_attention_scores=False,\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c754a3c-b07d-4995-8030-9fa8ac55da6e",
   "metadata": {},
   "source": [
    "## PositioningEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "583e2b43-e3cf-4f71-a8ac-607a9f458b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenAndPositionEmbedding(layers.Layer):\n",
    "    def __init__(self,maxlen, vocab_size, embed_dim):\n",
    "        super(TokenAndPositionEmbedding, self).__init__()\n",
    "        self.maxlen = maxlen\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_dim = embed_dim\n",
    "        self.token_emb = layers.Embedding(input_dim = vocab_size, output_dim = embed_dim)\n",
    "        self.pos_emb = layers.Embedding(input_dim = maxlen, output_dim = embed_dim)\n",
    "        \n",
    "    def call(self, x):\n",
    "        maxlen = tf.shape(x)[-1]\n",
    "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
    "        positions = self.pos_emb(positions)\n",
    "        x = self.token_emb(x)\n",
    "        return x + positions\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update(\n",
    "            {\n",
    "                \"max_len\": self.maxlen,\n",
    "                \"vocab_size\": self.vocab_size,\n",
    "                \"embed_dim\": self.embed_dim,\n",
    "            }\n",
    "        )\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d2bea77f-9363-4db9-90ca-57a106807118",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = layers.Input(shape=(None,), dtype=tf.int32)\n",
    "x = TokenAndPositionEmbedding(MAXLEN, VOCAB_SIZE, EMBEDDING_DIM)(inputs)\n",
    "x, attention_scores = TransformerBlock(N_HEADS, KEY_DIM, EMBEDDING_DIM, FEED_FORWARD_DIM)(x)\n",
    "outputs = layers.Dense(VOCAB_SIZE, activation =\"softmax\")(x)\n",
    "gpt = models.Model(inputs = inputs, outputs=[outputs, attention_scores])\n",
    "gpt.compile(\"adam\", loss=[losses.SparseCategoricalCrossentropy(), None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c5596c99-05db-4209-87ed-c1a9f04ba63d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, None)]            0         \n",
      "                                                                 \n",
      " token_and_position_embeddin  (None, None, 256)        2580480   \n",
      " g (TokenAndPositionEmbeddin                                     \n",
      " g)                                                              \n",
      "                                                                 \n",
      " transformer_block (Transfor  ((None, None, 256),      658688    \n",
      " merBlock)                    (None, 2, None, None))             \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, None, 10000)       2570000   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,809,168\n",
      "Trainable params: 5,809,168\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gpt.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "85d8a9df-61d8-4cac-bc10-c99eda10d3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"./checkpoint/checkpoints.ckpt\"\n",
    "ModelcheckPoint = keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_best_only=True,\n",
    "                                                 save_freq=\"epoch\",\n",
    "                                                 verbose=0,\n",
    "                                                 save_weights_only=True)\n",
    "EarlyStopping = keras.callbacks.EarlyStopping(monitor=\"loss\",\n",
    "                                             verbose=0,\n",
    "                                             mode=\"auto\",\n",
    "                                             patience=3,\n",
    "                                             min_delta=0.01,\n",
    "                                             )\n",
    "tensorboard = keras.callbacks.TensorBoard(log_dir=\"./logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4fd727-4aa5-4443-ade2-a99effd03777",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4faeb79e-3462-43db-8c32-b2e645756bea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3a72caa4-4d65-41bc-bb00-661e718bc8b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "   4/4060 [..............................] - ETA: 1:28 - loss: 8.7399 - dense_2_loss: 8.7399   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-16 11:09:57.851285: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4060/4060 [==============================] - ETA: 0s - loss: 2.2529 - dense_2_loss: 2.2529WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "4060/4060 [==============================] - 88s 21ms/step - loss: 2.2529 - dense_2_loss: 2.2529\n",
      "Epoch 2/15\n",
      "4060/4060 [==============================] - ETA: 0s - loss: 1.9563 - dense_2_loss: 1.9563WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "4060/4060 [==============================] - 86s 21ms/step - loss: 1.9563 - dense_2_loss: 1.9563\n",
      "Epoch 3/15\n",
      "4060/4060 [==============================] - ETA: 0s - loss: 1.8866 - dense_2_loss: 1.8866WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "4060/4060 [==============================] - 86s 21ms/step - loss: 1.8866 - dense_2_loss: 1.8866\n",
      "Epoch 4/15\n",
      "4060/4060 [==============================] - ETA: 0s - loss: 1.8446 - dense_2_loss: 1.8446WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "4060/4060 [==============================] - 86s 21ms/step - loss: 1.8446 - dense_2_loss: 1.8446\n",
      "Epoch 5/15\n",
      "4060/4060 [==============================] - ETA: 0s - loss: 1.8141 - dense_2_loss: 1.8141WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "4060/4060 [==============================] - 86s 21ms/step - loss: 1.8141 - dense_2_loss: 1.8141\n",
      "Epoch 6/15\n",
      "4058/4060 [============================>.] - ETA: 0s - loss: 1.7906 - dense_2_loss: 1.7906WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "4060/4060 [==============================] - 86s 21ms/step - loss: 1.7906 - dense_2_loss: 1.7906\n",
      "Epoch 7/15\n",
      "4060/4060 [==============================] - ETA: 0s - loss: 1.7717 - dense_2_loss: 1.7717WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "4060/4060 [==============================] - 86s 21ms/step - loss: 1.7717 - dense_2_loss: 1.7717\n",
      "Epoch 8/15\n",
      "4060/4060 [==============================] - ETA: 0s - loss: 1.7560 - dense_2_loss: 1.7560WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "4060/4060 [==============================] - 85s 21ms/step - loss: 1.7560 - dense_2_loss: 1.7560\n",
      "Epoch 9/15\n",
      "4060/4060 [==============================] - ETA: 0s - loss: 1.7421 - dense_2_loss: 1.7421WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "4060/4060 [==============================] - 86s 21ms/step - loss: 1.7421 - dense_2_loss: 1.7421\n",
      "Epoch 10/15\n",
      "4060/4060 [==============================] - ETA: 0s - loss: 1.7299 - dense_2_loss: 1.7299WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "4060/4060 [==============================] - 87s 21ms/step - loss: 1.7299 - dense_2_loss: 1.7299\n",
      "Epoch 11/15\n",
      "4060/4060 [==============================] - ETA: 0s - loss: 1.7191 - dense_2_loss: 1.7191WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "4060/4060 [==============================] - 86s 21ms/step - loss: 1.7191 - dense_2_loss: 1.7191\n",
      "Epoch 12/15\n",
      "4060/4060 [==============================] - ETA: 0s - loss: 1.7095 - dense_2_loss: 1.7095WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "4060/4060 [==============================] - 86s 21ms/step - loss: 1.7095 - dense_2_loss: 1.7095\n",
      "Epoch 13/15\n",
      "4060/4060 [==============================] - ETA: 0s - loss: 1.7006 - dense_2_loss: 1.7006WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "4060/4060 [==============================] - 86s 21ms/step - loss: 1.7006 - dense_2_loss: 1.7006\n",
      "Epoch 14/15\n",
      "4060/4060 [==============================] - ETA: 0s - loss: 1.6927 - dense_2_loss: 1.6927WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "4060/4060 [==============================] - 86s 21ms/step - loss: 1.6927 - dense_2_loss: 1.6927\n",
      "Epoch 15/15\n",
      "4060/4060 [==============================] - ETA: 0s - loss: 1.6854 - dense_2_loss: 1.6854WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "4060/4060 [==============================] - 84s 21ms/step - loss: 1.6854 - dense_2_loss: 1.6854\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc52810ea30>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt.fit(train_ds,\n",
    "        epochs= 15,\n",
    "       callbacks=[ModelcheckPoint, EarlyStopping, tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb6c586-99fc-4b4d-9282-2c119563d419",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
